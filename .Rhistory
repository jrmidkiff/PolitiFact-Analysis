View(total_topic_ratings)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(stringr)
library(tidytext)
library(scales)
library(RColorBrewer)
library(rvest)
library(forcats)
library(knitr)
library(BSDA)
#rm(list = ls())
#load("D:/Everything/R/Politifact Investigation/Final_Final_Workspace.RData")
page_series <- tibble(contains = str_detect(date, "December 1st, 2008"),
page_no = 1:length(date))
page_series <- page_series %>%
filter(contains == TRUE)
see_this_nov_2008 <- max(page_series$page_no)
V_Total_Ratings <- comma_format()(as.integer
(politifact_orig %>%
summarise(Total_Ratings = n())))
temp <- politifact_orig %>%
group_by(Type) %>%
summarise(Subtotal = n()) %>%
mutate(Proportion = round((Subtotal / sum(Subtotal)) * 100, 1),
Subtotal = comma_format()(Subtotal))
V_Flip_O_Meter_n <- temp %>%
filter(Type == "Flip-O-Meter") %>%
select(Subtotal)
V_Flip_O_Meter_prop <- temp %>%
filter(Type == "Flip-O-Meter") %>%
select(Proportion)
V_Truth_O_Meter_n <- temp %>%
filter(Type == "Truth-O-Meter") %>%
select(Subtotal)
V_Truth_O_Meter_prop <- temp %>%
filter(Type == "Truth-O-Meter") %>%
select(Proportion)
truth_o_meter_ratings <- politifact %>%
rename(Rating = rating) %>%
group_by(Rating) %>%
summarise(Total_Ratings = n()) %>%
mutate(Proportion = Total_Ratings / sum(Total_Ratings))
truth_o_meter_colors <- c("#E40602", "#E71F28", "#EE9022", "#FFD503", "#C3D52D", "#71BF44")
ggplot(truth_o_meter_ratings, aes(x = Rating, y = Proportion, fill = Rating)) +
labs(title = "PolitiFact Truth-O-Meter Ratings Since 2017") +
geom_col(color = "black", size = 1) +
geom_label(label = comma_format()(truth_o_meter_ratings$Total_Ratings)) +
scale_fill_manual(values = truth_o_meter_colors) +
scale_y_continuous(labels = percent) +
theme(legend.position = "none")
V_truthful <- truth_o_meter_ratings %>%
filter(Rating == c("Mostly True", "True")) %>%
summarise(Proportion = sum(Proportion)) %>%
mutate(Proportion = percent_format()(Proportion))
V_truthful <- as.vector(V_truthful$Proportion)
V_false <- truth_o_meter_ratings %>%
filter(Rating == c("Pants on Fire!", "False", "Mostly False")) %>%
summarise(Proportion = sum(Proportion)) %>%
mutate(Proportion = percent_format()(Proportion))
V_false <- as.vector(V_false$Proportion)
V_half_true <- truth_o_meter_ratings %>%
mutate(Proportion = percent_format()(Proportion)) %>%
filter(Rating == "Half-True")
V_half_true <- as.vector(V_half_true$Proportion)
locations <- politifact %>%
group_by(source) %>%
mutate(Founded = min(year(date))) %>%
group_by(source, Founded, politifact_location) %>%
summarise(Total_Ratings = n()) %>%
arrange(-Total_Ratings) %>%
ungroup() %>%
mutate(Proportion = percent_format()(Total_Ratings / sum(Total_Ratings))) %>%
rename(Issuer = source, Type = politifact_location)
locations <- locations %>%
add_column(Rank = 1:nrow(locations)) %>%
select(Rank, everything())
#Merging in the electoral votes for each state, from https://state.1keydata.com/state-electoral-votes.php
#don't forget DC
electoral_votes <- tribble(
~US_State,	~`Electoral Votes`,
"Alabama", 9,
"Montana", 3,
"Alaska", 3,
"Nebraska", 5,
"Arizona", 11,
"Nevada", 6,
"Arkansas", 6,
"New Hampshire", 4,
"California", 55,
"New Jersey", 14,
"Colorado", 9,
"New Mexico", 5,
"Connecticut", 7,
"New York", 29,
"Delaware", 3,
"North Carolina", 15,
"Florida", 29,
"North Dakota", 3,
"Georgia", 16,
"Ohio", 18,
"Hawaii", 4,
"Oklahoma", 7,
"Idaho", 4,
"Oregon", 7,
"Illinois", 20,
"Pennsylvania", 20,
"Indiana", 11,
"Rhode Island", 4,
"Iowa", 6,
"South Carolina", 9,
"Kansas", 6,
"South Dakota", 3,
"Kentucky", 8,
"Tennessee", 11,
"Louisiana", 8,
"Texas", 38,
"Maine", 4,
"Utah", 6,
"Maryland", 10,
"Vermont", 3,
"Massachusetts", 11,
"Virginia", 13,
"Michigan", 16,
"Washington", 12,
"Minnesota", 10,
"West Virginia", 5,
"Mississippi", 6,
"Wisconsin", 10,
"Missouri", 10,
"Wyoming", 3,
"Washington D.C.", 3)
locations <-
locations %>%
separate(Issuer, c("A", "State"), sep = 11, remove = FALSE)
locations <- left_join(locations, electoral_votes, by = c("State" = "US_State"))%>%
select(-A, -State) %>%
rename(`Total Ratings` = Total_Ratings) %>%
select(everything(), `Electoral Votes`)
top_x_issuers <- locations %>%
filter(Proportion >= 1) %>%
mutate(Cumulative_Sum = percent_format()(cumsum(
as.numeric(
str_replace_all(Proportion, "[[:punct:]]", "")) / 1000)))
values <- tibble(rating = levels(politifact$rating)[1:6], value = seq(-3, 2, 1)) %>%
mutate(rating = as_factor(rating),
rating = fct_relevel(rating, levels(politifact$rating)))
locations_rating <- politifact %>%
group_by(source, rating) %>%
summarise(Total_Ratings = n())
locations_rating <- left_join(locations_rating, values, by = "rating") %>%
mutate(score = Total_Ratings * value) %>%
summarise(Score = round((sum(score) / sum(Total_Ratings)), 3))
one_percent_issuers <- left_join(top_x_issuers, locations_rating, by = c("Issuer" = "source")) %>%
mutate(Issuer = factor(Issuer),
Issuer = fct_reorder(Issuer, Score)) %>%
arrange(Score)
one_percent_issuers <- one_percent_issuers %>%
mutate(cut = cut_interval(one_percent_issuers$Score, 12))
kable(locations, align = c("l", "l", "r", "r", "r", "r", "r"),
caption = "The Various PolitiFact Editions")
kable(values %>%
rename(`Statement Rating` = rating, `Truthfulness Score` = value) %>%
arrange(desc(`Truthfulness Score`)),
caption = "Truthfulness Score per Statement Rating")
ggplot(one_percent_issuers, aes(x = Issuer, y = Score, fill = cut)) +
labs(x = "PolitiFact Edition (i.e. who rated the statement?)",
y = "Average Truthfulness Rating",
title = "Mean Truthfulness Score by PolitiFact Edition") +
geom_col(color = "black", size = 1) +
geom_label(label = one_percent_issuers$Score) +
scale_x_discrete(labels = c(
"PolitiFact Wisconsin" = "PolitiFact\n Wisconsin",
"PolitiFact National" = "PolitiFact\n National",
"PolitiFact Rhode Island" = "PolitiFact\n Rhode Island",
"PolitiFact New Hampshire" = "PolitiFact\n New Hampshire",
"PolitiFact Virginia" = "PolitiFact\n Virginia",
"PolitiFact Texas" = "PolitiFact\n Texas",
"PolitiFact Florida" = "PolitiFact\n Florida",
"PolitiFact Oregon" = "PolitiFact\n Oregon",
"PolitiFact New Jersey" = "PolitiFact\n New Jersey",
"PolitiFact Ohio" = "PolitiFact\n Ohio",
"PolitiFact Georgia" = "PolitiFact\n Georgia")) +
scale_fill_manual(values = c("#E40602", "#D0240D", "#BD4318", "#AA6223", "#97812E", "#84A039", "#71BF44")) +
theme(legend.position = "none")
avg_score_all <- politifact %>%
group_by(rating) %>%
summarise(n = n())
avg_score_all <- left_join(avg_score_all, values, by = c("rating" = "rating")) %>%
mutate(score = value * n) %>%
summarise(avg_value = sum(score) / sum(n)) #The average score for PolitiFact Truth-O-Meter's history
year_score_all_pre_na <- politifact %>%
mutate(revised_date = date)
day(year_score_all_pre_na$revised_date) <- 1 #Setting all the days to day = 1 so that way they're grouped by month
year_score_all_pre_na <- year_score_all_pre_na %>%
group_by(revised_date, rating) %>%
summarise(n = n())
year_score_all_pre_na <- left_join(year_score_all_pre_na, values, by = c("rating" = "rating")) %>%
ungroup() %>%
mutate(Score = n * value) %>%
group_by(revised_date) %>%
summarise(Score = round((sum(Score) / sum(n)), 3),
Total_Ratings = sum(n))
year_score_all <- year_score_all_pre_na %>%
mutate(Score = ifelse(Total_Ratings < 30, NA, Score)) %>% #Only dealing with those with more than 30+ ratings a month
separate(revised_date, into = c("Year", "Month", "Junk"), remove = FALSE) %>%
mutate(Month = str_replace_all(Month, c("01" = "Jan", "02" = "Feb", "03" = "Mar",
"04" = "Apr", "05" = "May", "06" = "Jun",
"07" = "Jul", "08" = "Aug", "09" = "Sep",
"10" = "Oct", "11" = "Nov", "12" = "Dec"))) %>%
unite(Label, Month, Year, sep = " ") %>%
select(-Junk)
lowest_score_ever <- min(year_score_all$Score, na.rm = TRUE)
worst_month <- year_score_all %>%
filter(Score == lowest_score_ever) %>%
mutate(Label = str_replace_all(Label, c("Jan" = "January", "Feb" = "February", "Mar" = "March",
"Apr" = "April", "May" = "May", "Jun" = "June", "Jul" = "July",
"Aug" = "August","Sep" = "September", "Oct" = "October",
"Nov" = "November", "Dec" = "December")))
ggplot(year_score_all %>% slice(5:nrow(year_score_all)), #Lop off the first 4 rows because they're NA
aes(x = revised_date + 15, y = Score, fill = Score)) + #Add 15 days to each month so they align better
geom_rect(xmin = ymd("2016-Nov-8") - 365, xmax = ymd("2016-Nov-8"),
ymin = -3, ymax = 2, fill = "gray75", color = "black", linetype = "dashed", size = .8) +
geom_rect(xmin = ymd("2012-Nov-6") - 365, xmax = ymd("2012-Nov-6"),
ymin = -3, ymax = 2, fill = "gray75", color = "black", linetype = "dashed", size = .8) +
geom_rect(xmin = ymd("2008-Nov-4") - 365, xmax = ymd("2008-Nov-4"),
ymin = -3, ymax = 2, fill = "gray75", color = "black", linetype = "dashed", size = .8) +
geom_col(color = "black", size = 1) +
geom_smooth(size = 1.7, color = "royalblue4", se = FALSE) +
scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
scale_y_continuous(breaks = seq(-1.5, 0.5, 0.25)) +
scale_fill_continuous(low =  "#E40602", high = "#71BF44") +
theme(legend.position = "none",
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 10)) +
labs(x = "",
title = "PolitiFact Mean Truthfulness Score per Month",
subtitle = "Only months with 30 or more ratings are included. Shaded areas indicate the 12 months prior to a U.S. presidential election") +
geom_point(data = worst_month, aes(x = revised_date + 15, y = Score - .10),
size = 5, color = "black", fill = "red", shape = 24, stroke = 2,
inherit.aes = FALSE) +
geom_text(data = worst_month, aes(x = revised_date + 15, y = Score - .2),
label = "Minimum", inherit.aes = FALSE, color = "black", fontface = "bold")
trump_web_other <- politifact %>%
mutate(analysis = NA)
trump_web_other <- politifact %>%
mutate(analysis = ifelse(website == TRUE, "Website", NA),
analysis = ifelse(name == "Donald Trump", "Trump", analysis),
analysis = ifelse(is.na(analysis), "Other", analysis))
trump_web_analysis <- trump_web_other %>%
mutate(revised_date = date)
day(trump_web_analysis$revised_date) <- 1 #Setting all the days to day = 1 so that way they're grouped by month
trump_web_analysis <- trump_web_analysis %>%
group_by(revised_date, rating, analysis) %>%
summarise(n = n())
trump_web_analysis <- left_join(trump_web_analysis, values, by = c("rating" = "rating")) %>%
ungroup() %>%
mutate(Score = n * value) %>%
group_by(revised_date, analysis) %>%
summarise(subtotal = sum(Score),
Subtotal_Ratings = sum(n))
trump_web_analysis <- left_join(trump_web_analysis, year_score_all_pre_na) %>%
mutate(Sub_Score = round(subtotal / Total_Ratings, 3))
trump_web_analysis <- trump_web_analysis[c(1:4, 7, 5:6)] #Reordering columns
trump_web_analysis <- trump_web_analysis %>%
mutate(Score = ifelse(Total_Ratings < 5, NA, Score)) %>% #Only dealing with those with more than 30+ ratings a month
separate(revised_date, into = c("Year", "Month", "Junk"), remove = FALSE) %>%
mutate(Month = str_replace_all(Month, c("01" = "Jan", "02" = "Feb", "03" = "Mar",
"04" = "Apr", "05" = "May", "06" = "Jun",
"07" = "Jul", "08" = "Aug", "09" = "Sep",
"10" = "Oct", "11" = "Nov", "12" = "Dec"))) %>%
unite(Label, Month, Year, sep = " ") %>%
select(-Junk)
website_contribution_worst <- trump_web_analysis %>%
filter(revised_date %in% worst_month$revised_date,
analysis == "Website") %>%
mutate(percentage = Sub_Score / Score)
trump_contribution_worst <- trump_web_analysis %>%
filter(revised_date %in% worst_month$revised_date,
analysis == "Trump") %>%
mutate(percentage = Sub_Score / Score)
other_contribution_worst <- trump_web_analysis %>%
filter(revised_date %in% worst_month$revised_date,
analysis == "Other") %>%
mutate(percentage = Sub_Score / Score)
first_website <- politifact %>%
filter(website == TRUE) %>%
filter(date == min(date))
websites_by_month <- trump_web_analysis %>%
filter(analysis == "Website",
revised_date >= first_website$date[[1]]) %>%
mutate(pre_dec_2016 = ifelse(revised_date < "2016-12-01", "PRE", "POST")) %>%
group_by(pre_dec_2016) %>%
summarise(avg_per_month = round(sum(Subtotal_Ratings) / n(), 1),
months = n(),
avg_rating = round(sum(subtotal) / sum(Subtotal_Ratings), 3))
ggplot(trump_web_analysis %>% filter(revised_date >= mdy("January 1, 2014")),
aes(x = revised_date + 15, y = Sub_Score, fill = analysis,
color = analysis, group = analysis)) + #Add 15 days to each month so they align better
geom_rect(xmin = ymd("2016-Nov-8") - 365, xmax = ymd("2016-Nov-8"),
ymin = -3, ymax = 2, fill = "gray75", color = "black", linetype = "dashed", size = .8) +
geom_col(color = "black", size = 1) +
scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
scale_fill_manual("", values = c("Website" = "#c118ec", "Trump" = "#ffb00a", "Other" = "#808080"),
position = "bottom") +
scale_y_continuous(breaks = seq(-1.25, 0.5, 0.25)) +
labs(title = "PolitiFact Mean Truthfulness Score per Month, 2014 - Present",
x = "", y = "Monthly Average",
subtitle = "Shaded area indicates 12 months prior to the November 8, 2016 presidential election. Mean Truthfulness Scores are additive for Donald Trump, Websites, and Other.") +
theme(legend.position = "bottom",
legend.box.margin = margin(t = -20),
axis.text.x = element_text(size = 12),
axis.text.y = element_text(size = 10)) +
guides(fill = guide_legend(reverse = TRUE)) +
geom_point(data = worst_month, aes(x = revised_date + 15, y = Score - .10),
size = 5, color = "black", fill = "red", shape = 24, stroke = 2,
inherit.aes = FALSE) +
geom_text(data = worst_month, aes(x = revised_date + 15, y = Score - .2),
label = "Minimum", inherit.aes = FALSE, color = "black", fontface = "bold")
total_topics <- bind_cols(combined_scorecard, combined_count) %>%
mutate(count = as.integer(
str_extract(count, "\\d{1,4}")),
topic = str_replace_all(topic, "^\\s|\\s$", "")) %>%
select(-topic1)
total_topics <- total_topics %>%
mutate(scorecard = str_replace_all(scorecard, c("Half True" = "Half-True", "Pants on Fire$" = "Pants on Fire!")))
total_topics <- total_topics %>%
mutate(scorecard = str_replace_all(scorecard, c("Half True" = "Half-True", "Pants on Fire$" = "Pants on Fire!")))
total_topic_ratings <- left_join(total_topics, values, by = c("scorecard" = "rating")) %>%
mutate(Score = value * count) %>%
group_by(topic)
total_topic_summary <- total_topic_ratings %>%
summarise(total_ratings = sum(count),
total_score = sum(Score)) %>%
mutate(Avg_Score = total_score / total_ratings) %>%
mutate(Pos_Neg = ifelse(Avg_Score >= 0, "Positive", "Negative"))
table_of_topics <- total_topic_summary %>%
filter(rank(desc(total_ratings)) < 11) %>%
arrange(desc(total_ratings)) %>%
mutate(`Mean Truthfulness Score` = round(Avg_Score, 3),
`Total Ratings` = comma_format()(total_ratings)) %>%
rename(Subject = topic) %>%
mutate(Rank = 1:10) %>%
select(Rank, Subject, `Total Ratings`, `Mean Truthfulness Score`)
kable(table_of_topics, align = c("c", "l", "r", "r"),
caption = "Most Discussed Subjects in PolitiFact Ratings")
rm(total_topic_ratings, total_topic_summary, total_topics)
total_topics <- bind_cols(combined_scorecard, combined_count) %>%
mutate(count = as.integer(
str_extract(count, "\\d{1,4}")),
topic = str_replace_all(topic, "^\\s|\\s$", "")) %>%
select(-topic1)
total_topics <- total_topics %>%
mutate(scorecard = str_replace_all(scorecard, c("Half True" = "Half-True", "Pants on Fire$" = "Pants on Fire!")))
total_topic_ratings <- left_join(total_topics, values, by = c("scorecard" = "rating")) %>%
mutate(Score = value * count) %>%
group_by(topic)
total_topic_summary <- total_topic_ratings %>%
summarise(total_ratings = sum(count),
total_score = sum(Score)) %>%
mutate(Avg_Score = total_score / total_ratings) %>%
mutate(Pos_Neg = ifelse(Avg_Score >= 0, "Positive", "Negative"))
table_of_topics <- total_topic_summary %>%
filter(rank(desc(total_ratings)) < 11) %>%
arrange(desc(total_ratings)) %>%
mutate(`Mean Truthfulness Score` = round(Avg_Score, 3),
`Total Ratings` = comma_format()(total_ratings)) %>%
rename(Subject = topic) %>%
mutate(Rank = 1:10) %>%
select(Rank, Subject, `Total Ratings`, `Mean Truthfulness Score`)
kable(table_of_topics, align = c("c", "l", "r", "r"),
caption = "Most Discussed Subjects in PolitiFact Ratings")
# Follow these directions STEP BY STEP http://nickstrayer.me/RMarkdown_Sites_tutorial/
# Must always have an index.Rmd file
# Must always save the index.Rmd and the other .Rmd files running the below commands
setwd("D:/Everything/R/Politifact Investigation/PolitiFact-Analysis/PolitiFact-Analysis")
rmarkdown::render_site()
democrats
party_statistical_test
democrats
republicans
party_politicians <- verified_people_speakers %>%
group_by(Party, rating) %>%
summarise(`Total Statements` = sum(n))
party_politicians <- left_join(party_politicians, values, by = c("rating" = "rating")) %>%
mutate(score = value * `Total Statements`) %>%
group_by(Party) %>%
summarise(Total_Statements = sum(`Total Statements`),
Score = sum(score)) %>%
mutate(Final_Ratings = Score / Total_Statements)
added_row <- tibble(Party = "Average Major U.S. Politician",
Total_Statements = sum(party_politicians$Total_Statements),
Score = sum(party_politicians$Score),
Final_Ratings = Score / Total_Statements)
party_politicians <- party_politicians %>%
bind_rows(added_row) %>%
mutate(Party = as_factor(Party),
Party = fct_relevel(Party, "Average Major U.S. Politician", after = 2))
ggplot(party_politicians, aes(x = Party, y = Final_Ratings, fill = Party,
label = round(Final_Ratings, 3))) +
geom_col(size = 1, color = "black") +
scale_fill_manual(values = c("Democratic" = "#1A80C4", "Republican" = "#CC3D3D", "Average Major U.S. Politician" = "#735F81"), guide = "none") +
labs(x = "", y = "",
title = "Mean Truthfulness Score for Major Politicians' Statements by Party",
subtitle = str_c("Includes ",
comma_format()(sum(party_politicians %>%
filter(Party == c("Democratic", "Republican")) %>%
select(Total_Statements))),
" statements rated by PolitiFact from ",
nrow(verified_people_speakers %>%
group_by(name) %>%
summarise(n = n())),
" current and recent major U.S. politicians, including:\nPresidents, Vice-Presidents, Presidential Candidates, Senators, Representatives, and Governors.")) +
geom_hline(yintercept = 0, size = 1.5, linetype = "twodash") +
geom_vline(xintercept = 2.5, size = 1.5, linetype = "solid") +
theme(axis.text = element_text(size = 12),
axis.text.x = element_text(color = c("#1A80C4", "#CC3D3D", "#735F81"), face = "bold"),
panel.grid.major.x = element_blank()) +
geom_label()
final_test <- z.test(x = democrats$value, y = republicans$value,
sigma.x = sd(democrats$value), sigma.y = sd(republicans$value),
alternative = "two.sided", conf.level = 0.99)
save.image("D:/Everything/R/Politifact Investigation/Final_Final_Workspace.Rdata") #Save the workspace so I can use it in the second one
# Follow these directions STEP BY STEP http://nickstrayer.me/RMarkdown_Sites_tutorial/
# Must always have an index.Rmd file
# Must always save the index.Rmd and the other .Rmd files running the below commands
setwd("D:/Everything/R/Politifact Investigation/PolitiFact-Analysis/PolitiFact-Analysis")
rmarkdown::render_site()
# Follow these directions STEP BY STEP http://nickstrayer.me/RMarkdown_Sites_tutorial/
# Must always have an index.Rmd file
# Must always save the index.Rmd and the other .Rmd files running the below commands
setwd("D:/Everything/R/Politifact Investigation/PolitiFact-Analysis/PolitiFact-Analysis")
rmarkdown::render_site()
name
webpage
load("D:/Everything/R/Politifact Investigation/Final_Final_Workspace.Rdata")
final_test
politifact
unique(politifact$website)
unique(politifact$Type)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(stringr)
library(tidytext)
library(scales)
library(RColorBrewer)
library(rvest)
library(forcats)
library(knitr)
library(BSDA)
rm(list = ls()) #Careful, this will wipe out your environment
#Note to self, if the data is fresh and you don't want to rerun everything, comment all code sections and put in
load("D:/Everything/R/Politifact Investigation/Final_Final_Workspace.RData")
# Scrape#########
# I recommend that you minimize everything (Alt + O) and then uncover it section by section as you go through it since it's a lot of code. I'm going to clear the envirnoment first and then save everything as an image that I can then use for the other page without code.
webpage <- read_html("http://www.politifact.com/truth-o-meter/statements/")
no_pages <- html_text(html_nodes(webpage, '.step-links__current'))
no_pages <- as.integer(
str_extract(no_pages, "\\d{3,4}(?=\n)"))
name <- vector("list", length = no_pages)
source <- vector("list", length = no_pages)
date <- vector("list", length = no_pages)
picture_rating <- vector("list", length = no_pages)
statement_text <- vector("list", length = no_pages)
explanation_text <- vector("list", length = no_pages)
rating <- vector("list", length = no_pages)
for (i in seq_along(1:length(name))) {
webpage <- read_html(
str_c("http://www.politifact.com/truth-o-meter/statements/?page=", i))
politifact_scrape <- function(x) {
as_tibble(
html_text(
html_nodes(webpage, x)))
}
name[[i]] <- politifact_scrape('.statement__source a')
source[[i]] <- politifact_scrape('.statement__edition a')
date[[i]] <- politifact_scrape('.article__meta')
statement_text[[i]] <- politifact_scrape('.statement__text')
explanation_text[[i]] <- politifact_scrape('.quote')
#Take the image, use the alt-text to find the rating
attributes <- html_attrs(
html_nodes(webpage, '.meter img'))
for (j in seq_along(attributes)) {
rating[[i]][[j]] <- attributes[[j]][[2]]
}
rating[[i]] <- as_tibble(rating[[i]])
Sys.sleep(time = 3) # Do a 3 second pause before running the loop again
# This should take approximately 4 seconds (1 second of 'for loop' run time
# plus a 3 second mandatory wait) times 700-some pages divided by 60 seconds per
# minute = ~50 minutes
}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(stringr)
library(tidytext)
library(scales)
library(RColorBrewer)
library(rvest)
library(forcats)
library(knitr)
library(BSDA)
rm(list = ls()) #Careful, this will wipe out your environment
#Note to self, if the data is fresh and you don't want to rerun everything, comment all code sections and put in
load("D:/Everything/R/Politifact Investigation/Final_Final_Workspace.RData")
# Follow these directions STEP BY STEP http://nickstrayer.me/RMarkdown_Sites_tutorial/
# Must always have an index.Rmd file
# Must always save the index.Rmd and the other .Rmd files running the below commands
setwd("D:/Everything/R/Politifact Investigation/PolitiFact-Analysis/PolitiFact-Analysis")
rmarkdown::render_site()
